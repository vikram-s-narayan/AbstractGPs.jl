<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>The Main APIs · AbstractGPs.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">AbstractGPs.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>The Main APIs</a><ul class="internal"><li><a class="tocitem" href="#Intended-Audience"><span>Intended Audience</span></a></li><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#FiniteGP-APIs"><span>FiniteGP APIs</span></a></li><li><a class="tocitem" href="#Internal-AbstractGPs-API"><span>Internal AbstractGPs API</span></a></li><li><a class="tocitem" href="#Which-API-should-I-implement?"><span>Which API should I implement?</span></a></li></ul></li><li><a class="tocitem" href="../concrete_features/">Concrete Features</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/regression_1d/">One-dimensional regression</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>The Main APIs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>The Main APIs</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/master/docs/src/api.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="FiniteGP-and-AbstractGP"><a class="docs-heading-anchor" href="#FiniteGP-and-AbstractGP">FiniteGP and AbstractGP</a><a id="FiniteGP-and-AbstractGP-1"></a><a class="docs-heading-anchor-permalink" href="#FiniteGP-and-AbstractGP" title="Permalink"></a></h1><h2 id="Intended-Audience"><a class="docs-heading-anchor" href="#Intended-Audience">Intended Audience</a><a id="Intended-Audience-1"></a><a class="docs-heading-anchor-permalink" href="#Intended-Audience" title="Permalink"></a></h2><p>This page is intended for developers. If you are a user, please refer to our other examples.</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>AbstractGPs provides the abstract type <code>AbstractGP</code>, and the concrete type <code>FiniteGP</code>. An <code>AbstractGP</code>, <code>f</code>, should be thought of as a distribution over functions. This means that the output of <code>rand(f)</code> would be a real-valued function. It&#39;s not usually possible to implement this though, so we don&#39;t.</p><p>A <code>FiniteGP</code> <code>fx = f(x)</code> represents the distribution over functions at the finite collection of points specified in <code>x</code>. <code>fx</code> is a multivariate Normal distribution, so <code>rand(fx)</code> produces a <code>Vector</code> of <code>Real</code>s.</p><p>A <code>FiniteGP</code> is the interesting object computationally, so if you create a new subtype <code>MyNewGP</code> of <code>AbstractGP</code>, and wish to make it interact well with the rest of the GP ecosystem, the methods that you must implement are not those directly involving <code>MyNewGP</code>, but rather those involving</p><pre><code class="language-julia">FiniteGP{&lt;:MyNewGP}</code></pre><p>We provide two ways in which to do this. The first is to implement methods directly on <code>Finite{&lt;:MyNewGP}</code> – this is detailed in the <a href="#FiniteGP-APIs">FiniteGP APIs</a>. The second is to implement some methods directly involving <code>MyNewGP</code>, and utilise default <code>FiniteGP</code> methods implemented in terms of these – this is detailed in the <a href="#Internal-AbstractGPs-API">Internal AbstractGPs API</a>. For example, the first method involves implementing methods like <code>AbstractGPs.mean(fx::FiniteGP{&lt;:MyNewGP})</code>, while the second involves <code>AbstractGPs.mean(f::MyNewGP, x::AbstractVector)</code>.</p><p>The second interface is generally easier to implement, but sometimes it isn&#39;t always appropriate. See <a href="#Which-API-should-I-implement?">Which API should I implement?</a> for further discussion.</p><h2 id="FiniteGP-APIs"><a class="docs-heading-anchor" href="#FiniteGP-APIs">FiniteGP APIs</a><a id="FiniteGP-APIs-1"></a><a class="docs-heading-anchor-permalink" href="#FiniteGP-APIs" title="Permalink"></a></h2><p>Let <code>f</code> be an <code>AbstractGP</code>, <code>x</code> an <code>AbstractVector</code> representing a collection of inputs, and <code>Σ</code> a positive-definite matrix of size <code>(length(x), length(x))</code>. A <code>FiniteGP</code> represents the multivariate Gaussian induced by &quot;indexing&quot; into <code>f</code> at each point in <code>x</code>, and adding independent zero-mean noise with covariance matrix <code>Σ</code>:</p><pre><code class="language-julia">fx = f(x, Σ)

# The code below is equivalent to the above, and is just for reference.
# When writing code, prefer the above syntax.
fx = AbstractGPs.FiniteGP(f, x, Σ)</code></pre><p>The <code>FiniteGP</code> has two API levels. The <a href="#Primary-Public-API">Primary Public API</a> should be supported by all <code>FiniteGP</code>s, while the <a href="#Secondary-Public-API">Secondary Public API</a> will only be supported by a subset. Use only the primary API when possible.</p><h3 id="Primary-Public-API"><a class="docs-heading-anchor" href="#Primary-Public-API">Primary Public API</a><a id="Primary-Public-API-1"></a><a class="docs-heading-anchor-permalink" href="#Primary-Public-API" title="Permalink"></a></h3><p>These are user-facing methods. You can expect them to be implemented whenever you encounter a <code>FiniteGP</code>. If you are building something on top of AbstractGPs, try to implement it in terms of these functions.</p><h4 id="Required-Methods"><a class="docs-heading-anchor" href="#Required-Methods">Required Methods</a><a id="Required-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Required-Methods" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="Base.rand" href="#Base.rand"><code>Base.rand</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rand(rng::AbstractRNG, f::FiniteGP, N::Int=1)</code></pre><p>Obtain <code>N</code> independent samples from the marginals <code>f</code> using <code>rng</code>. Single-sample methods produce a <code>length(f)</code> vector. Multi-sample methods produce a <code>length(f)</code> x <code>N</code> <code>Matrix</code>.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern32Kernel());

julia&gt; x = randn(11);

julia&gt; rand(f(x)) isa Vector{Float64}
true

julia&gt; rand(MersenneTwister(123456), f(x)) isa Vector{Float64}
true

julia&gt; rand(f(x), 3) isa Matrix{Float64}
true

julia&gt; rand(MersenneTwister(123456), f(x), 3) isa Matrix{Float64}
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/finite_gp.jl#LL202-L226">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.marginals" href="#AbstractGPs.marginals"><code>AbstractGPs.marginals</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">marginals(f::FiniteGP)</code></pre><p>Compute a vector of Normal distributions representing the marginals of <code>f</code> efficiently. In particular, the off-diagonal elements of <code>cov(f(x))</code> are never computed.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern32Kernel());

julia&gt; x = randn(11);

julia&gt; fs = marginals(f(x));

julia&gt; mean.(fs) == mean(f(x))
true

julia&gt; std.(fs) == sqrt.(diag(cov(f(x))))
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/finite_gp.jl#LL176-L196">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Distributions.logpdf-Tuple{AbstractGPs.FiniteGP, AbstractVector{var&quot;#s56&quot;} where var&quot;#s56&quot;&lt;:Real}" href="#Distributions.logpdf-Tuple{AbstractGPs.FiniteGP, AbstractVector{var&quot;#s56&quot;} where var&quot;#s56&quot;&lt;:Real}"><code>Distributions.logpdf</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">logpdf(f::FiniteGP, y::AbstractVecOrMat{&lt;:Real})</code></pre><p>The logpdf of <code>y</code> under <code>f</code> if is <code>y isa AbstractVector</code>. logpdf of each column of <code>y</code> if <code>y isa Matrix</code>.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern32Kernel());

julia&gt; x = randn(11);

julia&gt; y = rand(f(x));

julia&gt; logpdf(f(x), y) isa Real
true

julia&gt; Y = rand(f(x), 3);

julia&gt; logpdf(f(x), Y) isa AbstractVector{&lt;:Real}
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/finite_gp.jl#LL236-L258">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.posterior-Tuple{AbstractGPs.FiniteGP, AbstractVector{var&quot;#s56&quot;} where var&quot;#s56&quot;&lt;:Real}" href="#AbstractGPs.posterior-Tuple{AbstractGPs.FiniteGP, AbstractVector{var&quot;#s56&quot;} where var&quot;#s56&quot;&lt;:Real}"><code>AbstractGPs.posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">posterior(fx::FiniteGP, y::AbstractVector{&lt;:Real})</code></pre><p>Constructs the posterior distribution over <code>fx.f</code> given observations <code>y</code> at <code>x</code> made under noise <code>fx.Σy</code>. This is another <code>AbstractGP</code> object. See chapter 2 of [1] for a recap on exact inference in GPs. This posterior process has mean function</p><pre><code class="language-julia">m_posterior(x) = m(x) + k(x, fx.x) inv(cov(fx)) (y - mean(fx))</code></pre><p>and kernel</p><pre><code class="language-julia">k_posterior(x, z) = k(x, z) - k(x, fx.x) inv(cov(fx)) k(fx.x, z)</code></pre><p>where <code>m</code> and <code>k</code> are the mean function and kernel of <code>fx.f</code> respectively.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/posterior_gp/posterior_gp.jl#LL6-L20">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.mean-Tuple{AbstractGPs.FiniteGP}" href="#Statistics.mean-Tuple{AbstractGPs.FiniteGP}"><code>Statistics.mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean(fx::FiniteGP)</code></pre><p>Compute the mean vector of <code>fx</code>.</p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern52Kernel());

julia&gt; x = randn(11);

julia&gt; mean(f(x)) == zeros(11)
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/finite_gp.jl#LL33-L47">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.var-Tuple{AbstractGPs.FiniteGP}" href="#Statistics.var-Tuple{AbstractGPs.FiniteGP}"><code>Statistics.var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">var(f::FiniteGP)</code></pre><p>Compute only the diagonal elements of <a href="#Statistics.cov-Tuple{AbstractGPs.FiniteGP}"><code>cov(f)</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; fx = GP(Matern52Kernel())(randn(10), 0.1);

julia&gt; var(fx) == diag(cov(fx))
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/finite_gp.jl#LL94-L107">source</a></section></article><h4 id="Optional-methods"><a class="docs-heading-anchor" href="#Optional-methods">Optional methods</a><a id="Optional-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Optional-methods" title="Permalink"></a></h4><p>Default implementations are provided for these, but you may wish to specialise for performance.</p><article class="docstring"><header><a class="docstring-binding" id="StatsBase.mean_and_var-Tuple{AbstractGPs.FiniteGP}" href="#StatsBase.mean_and_var-Tuple{AbstractGPs.FiniteGP}"><code>StatsBase.mean_and_var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean_and_var(f::FiniteGP)</code></pre><p>Compute both <code>mean(f)</code> and the diagonal elements of <code>cov(f)</code>.</p><p>Sometimes more efficient than computing them separately, particularly for posteriors.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; fx = GP(SqExponentialKernel())(range(-3.0, 3.0; length=10), 0.1);

julia&gt; mean_and_var(fx) == (mean(fx), var(fx))
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/finite_gp.jl#LL132-L147">source</a></section></article><h3 id="Secondary-Public-API"><a class="docs-heading-anchor" href="#Secondary-Public-API">Secondary Public API</a><a id="Secondary-Public-API-1"></a><a class="docs-heading-anchor-permalink" href="#Secondary-Public-API" title="Permalink"></a></h3><p>While the covariance matrix of any multivariate Gaussian is defined, it is not always a good idea to actually compute it. Fortunately, it&#39;s often the case that you&#39;re not actually interested in the covariance matrix per-se, rather the other quantities that you might use it to compute (<code>logpdf</code>, <code>rand</code>, <code>posterior</code>). This is similar to the well-known observation that you rarely need the inverse of a matrix, you just need to compute the inverse multiplied by something, so it&#39;s considered good practice to avoid ever explicitly computing the inverse of a matrix so as to avoid the numerical issues associated with it. This is important, for example, as <a href="https://github.com/JuliaGaussianProcesses/TemporalGPs.jl">TemporalGPs.jl</a> is able to <a href="https://github.com/JuliaGaussianProcesses/TemporalGPs.jl/blob/master/src/gp/lti_sde.jl">implement</a> all of the <a href="#Primary-Public-API">Primary Public API</a> in linear time in the dimension of the <code>FiniteGP</code>, as it never needs to evaluate the covariance matrix.</p><p>However, for many (probably the majority of) GPs, this acceleration isn&#39;t possible, and there is really nothing lost by explicitly evaluating the covariance matrix. We call this the <a href="#Secondary-Public-API">Secondary Public API</a>, because it&#39;s available a large proportion of the time, but should be avoided if at all possible.</p><h4 id="Required-Methods-2"><a class="docs-heading-anchor" href="#Required-Methods-2">Required Methods</a><a class="docs-heading-anchor-permalink" href="#Required-Methods-2" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{AbstractGPs.FiniteGP}" href="#Statistics.cov-Tuple{AbstractGPs.FiniteGP}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cov(f::FiniteGP)</code></pre><p>Compute the covariance matrix of <code>fx</code>.</p><p><strong>Noise-free observations</strong></p><pre><code class="language-julia-repl">julia&gt; f = GP(Matern52Kernel());

julia&gt; x = randn(11);

julia&gt; cov(f(x)) == kernelmatrix(Matern52Kernel(), x)
true</code></pre><p><strong>Isotropic observation noise</strong></p><pre><code class="language-julia-repl">julia&gt; cov(f(x, 0.1)) == kernelmatrix(Matern52Kernel(), x) + 0.1 * I
true</code></pre><p><strong>Independent anisotropic observation noise</strong></p><pre><code class="language-julia-repl">julia&gt; s = rand(11);

julia&gt; cov(f(x, s)) == kernelmatrix(Matern52Kernel(), x) + Diagonal(s)
true</code></pre><p><strong>Correlated observation noise</strong></p><pre><code class="language-julia-repl">julia&gt; A = randn(11, 11); S = A&#39;A;

julia&gt; cov(f(x, S)) == kernelmatrix(Matern52Kernel(), x) + S
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/finite_gp.jl#LL50-L91">source</a></section></article><h4 id="Optional-Methods"><a class="docs-heading-anchor" href="#Optional-Methods">Optional Methods</a><a id="Optional-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Optional-Methods" title="Permalink"></a></h4><p>Default implementations are provided for these, but you may wish to specialise for performance.</p><article class="docstring"><header><a class="docstring-binding" id="StatsBase.mean_and_cov-Tuple{AbstractGPs.FiniteGP}" href="#StatsBase.mean_and_cov-Tuple{AbstractGPs.FiniteGP}"><code>StatsBase.mean_and_cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean_and_cov(f::FiniteGP)</code></pre><p>Equivalent to <code>(mean(f), cov(f))</code>, but sometimes more efficient to compute them jointly than separately.</p><pre><code class="language-julia-repl">julia&gt; fx = GP(SqExponentialKernel())(range(-3.0, 3.0; length=10), 0.1);

julia&gt; mean_and_cov(fx) == (mean(fx), cov(fx))
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/finite_gp.jl#LL113-L126">source</a></section></article><h2 id="Internal-AbstractGPs-API"><a class="docs-heading-anchor" href="#Internal-AbstractGPs-API">Internal AbstractGPs API</a><a id="Internal-AbstractGPs-API-1"></a><a class="docs-heading-anchor-permalink" href="#Internal-AbstractGPs-API" title="Permalink"></a></h2><p>This functionality is not intended to be used directly by the users, or those building functionality on top of this package – they should interact with <a href="#Primary-Public-API">Primary Public API</a>.</p><p>As discussed at the top of this page, instances of subtypes of <code>AbstractGP</code> represent Gaussian processes – collections of jointly-Gaussian random variables, which may be infinite-dimensional.</p><p>Implementing the following API for your own <code>AbstractGP</code> subtype automatically implements both the Primary and Secondary public APIs above in terms of them.</p><p>Existing implementations of this interface include</p><ol><li><a href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/3b5de4f4da80e4e3a7dcf716764b298d953a0b37/src/gp/gp.jl#L56"><code>GP</code></a></li><li><a href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/3b5de4f4da80e4e3a7dcf716764b298d953a0b37/src/posterior_gp/posterior_gp.jl#L1"><code>PosteriorGP</code></a></li><li><a href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/3b5de4f4da80e4e3a7dcf716764b298d953a0b37/src/posterior_gp/approx_posterior_gp.jl#L4"><code>ApproxPosteriorGP</code></a></li><li><a href="https://github.com/JuliaGaussianProcesses/Stheno.jl/blob/b4e2d20f973a0816272fdf07bdd5896a614b99e1/src/gp/gp.jl#L11"><code>WrappedGP</code></a></li><li><a href="https://github.com/JuliaGaussianProcesses/Stheno.jl/blob/b4e2d20f973a0816272fdf07bdd5896a614b99e1/src/composite/composite_gp.jl#L7"><code>CompositeGP</code></a></li><li><a href="https://github.com/JuliaGaussianProcesses/Stheno.jl/blob/b4e2d20f973a0816272fdf07bdd5896a614b99e1/src/gaussian_process_probabilistic_programme.jl#L8"><code>GaussianProcessProbabilisticProgramme</code></a></li></ol><h4 id="Required-Methods-3"><a class="docs-heading-anchor" href="#Required-Methods-3">Required Methods</a><a class="docs-heading-anchor-permalink" href="#Required-Methods-3" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="Statistics.mean-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}" href="#Statistics.mean-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}"><code>Statistics.mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean(f::AbstractGP, x::AbstractVector)</code></pre><p>Computes the mean vector of the multivariate Normal <code>f(x)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/abstract_gp.jl#LL14-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T, AbstractVector{T} where T}" href="#Statistics.cov-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T, AbstractVector{T} where T}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cov(f::AbstractGP, x::AbstractVector, y::AbstractVector)</code></pre><p>Compute the <code>length(x)</code> by <code>length(y)</code> cross-covariance matrix between <code>f(x)</code> and <code>f(y)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/abstract_gp.jl#LL35-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Statistics.var-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}" href="#Statistics.var-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}"><code>Statistics.var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">var(f::AbstractGP, x::AbstractVector)</code></pre><p>Compute only the diagonal elements of <code>cov(f(x))</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/abstract_gp.jl#LL28-L32">source</a></section></article><h4 id="Optional-Methods-2"><a class="docs-heading-anchor" href="#Optional-Methods-2">Optional Methods</a><a class="docs-heading-anchor-permalink" href="#Optional-Methods-2" title="Permalink"></a></h4><p>Default implementations are provided for these, but you may wish to specialise for performance.</p><article class="docstring"><header><a class="docstring-binding" id="Statistics.cov-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}" href="#Statistics.cov-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}"><code>Statistics.cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cov(f::AbstractGP, x::AbstractVector)</code></pre><p>Compute the <code>length(x)</code> by <code>length(x)</code> covariance matrix of the multivariate Normal <code>f(x)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/abstract_gp.jl#LL21-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsBase.mean_and_cov-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}" href="#StatsBase.mean_and_cov-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}"><code>StatsBase.mean_and_cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean_and_cov(f::AbstractGP, x::AbstractVector)</code></pre><p>Compute both <code>mean(f(x))</code> and <code>cov(f(x))</code>. Sometimes more efficient than separately computation, particularly for posteriors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/abstract_gp.jl#LL42-L47">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsBase.mean_and_var-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}" href="#StatsBase.mean_and_var-Tuple{AbstractGPs.AbstractGP, AbstractVector{T} where T}"><code>StatsBase.mean_and_var</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mean_and_var(f::AbstractGP, x::AbstractVector)</code></pre><p>Compute both <code>mean(f(x))</code> and the diagonal elements of <code>cov(f(x))</code>. Sometimes more efficient than separately computation, particularly for posteriors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/a05b025ce0dbc02eca768e04c0ebb93916ac696c/src/abstract_gp/abstract_gp.jl#LL50-L55">source</a></section></article><p>Note that, while we <em>could</em> provide a default implementation for <code>var(f, x)</code> as <code>diag(cov(f, x))</code>, this is generally such an inefficient fallback, that we find it preferable to error if it&#39;s not implemented than to ever hit a fallback.</p><h2 id="Which-API-should-I-implement?"><a class="docs-heading-anchor" href="#Which-API-should-I-implement?">Which API should I implement?</a><a id="Which-API-should-I-implement?-1"></a><a class="docs-heading-anchor-permalink" href="#Which-API-should-I-implement?" title="Permalink"></a></h2><p>To answer this question, you need to need to know whether or not the default implementations of the <a href="#FiniteGP-APIs">FiniteGP APIs</a> work for your use case. There are a couple of reasons of which we are aware for why this might not be the case (see below) – possibly there are others.</p><p>If you are unsure, please open an issue to discuss.</p><h3 id="You-want-to-avoid-computing-the-covariance-matrix"><a class="docs-heading-anchor" href="#You-want-to-avoid-computing-the-covariance-matrix">You want to avoid computing the covariance matrix</a><a id="You-want-to-avoid-computing-the-covariance-matrix-1"></a><a class="docs-heading-anchor-permalink" href="#You-want-to-avoid-computing-the-covariance-matrix" title="Permalink"></a></h3><p>We&#39;ve already discussed this a bit on this page. The default implementations of the <a href="#FiniteGP-APIs">FiniteGP APIs</a> rely on computing the covariance matrix. If your <code>AbstractGP</code> subtype needs to avoid computing the covariance matrix for performance reasons, then do <em>not</em> implement the <a href="#Internal-AbstractGPs-API">Internal AbstractGPs API</a>. <em>Do</em> implement the <a href="#Primary-Public-API">Primary Public API</a>. Do <em>not</em> implement the <a href="#Secondary-Public-API">Secondary Public API</a>.</p><p><a href="https://github.com/JuliaGaussianProcesses/TemporalGPs.jl">TemporalGPs.jl</a> is an example of a package that does this – see the <a href="https://github.com/JuliaGaussianProcesses/TemporalGPs.jl/blob/24343744cf60a50e09b301dee6f14b03cba7ccba/src/gp/lti_sde.jl#L7"><code>LTISDE</code></a> implementation for an example. The same is true of the <a href="https://github.com/JuliaGaussianProcesses/BayesianLinearRegressors.jl/blob/ea20b1bb0603d27c67b3751ad2cf26e271b7acaa/src/bayesian_linear_regression.jl#L11"><code>BayesianLinearRegressor</code></a> type.</p><h3 id="You-don&#39;t-want-to-use-the-default-implementations"><a class="docs-heading-anchor" href="#You-don&#39;t-want-to-use-the-default-implementations">You don&#39;t want to use the default implementations</a><a id="You-don&#39;t-want-to-use-the-default-implementations-1"></a><a class="docs-heading-anchor-permalink" href="#You-don&#39;t-want-to-use-the-default-implementations" title="Permalink"></a></h3><p>Perhaps you just don&#39;t like the default implementations because you don&#39;t want to make use of Cholesky factorisations. We don&#39;t have an example of this yet in Julia, however <a href="https://gpytorch.ai/">GPyTorch</a> avoids the Cholesky factorisation in favour of iterative solvers.</p><p>In this situation, implement <em>both</em> the <a href="#Internal-AbstractGPs-API">Internal AbstractGPs API</a> <em>and</em> the <a href="#FiniteGP-APIs">FiniteGP APIs</a>.</p><p>In this situation you will benefit less from code reuse inside AbstractGPs, but will continue to benefit from the ability of others use your code, and to take advantage of any existing functionality which requires types which adhere to the AbstractGPs API.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../concrete_features/">Concrete Features »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 3 June 2021 02:05">Thursday 3 June 2021</span>. Using Julia version 1.6.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
